{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Using Labeled Data to Train a Network, Use The Network to Label New Videos, and Create Trajectories </h1> \n",
    "<p> Use another notebook create a project, extract frames, and label training/testing data </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RK255E7YoEIt"
   },
   "source": [
    "This notebook illustrates how to:\n",
    "- train a network\n",
    "- evaluate a network\n",
    "- analyze a novel video\n",
    "\n",
    "many of the functions have additional parameters / complexity, see the DLC docs for more inf on each.\n",
    "\n",
    "This assumes you already have a project folder with labeled data! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4C5WRoS9g5Od",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# make sure you graphic driver is accessable\n",
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HxVNyimFp-PJ",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# check the tensorflow version\n",
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> The following is very important as it allows the current GPU process to grow dynamically </h1>\n",
    "Without this option tf will likely run out of VRAM when trying to update the weight tensor. In theory, these options could cause the GPU to run out of memory entirely, but there is no other way to allow training to complete successfully. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#allow video memory growth as network expands to avoid convolutional network errors\n",
    "TF_FORCE_GPU_ALLOW_GROWTH = True\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pm_PC1Q8lRrH",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#let's make sure we see a GPU:\n",
    "#tf.test.gpu_device_name()\n",
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start here for training DeepLabCut and analyzing new videos!\n",
    "<p><br>If the first imports fail, there is again - sadly - an issue with you enviroment. Make sure all packages beside DLC are installed via conda. </p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sXufoX6INe6w",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#GUIs don't work on in Docker (or the cloud), so label your data locally on your computer! \n",
    "#This notebook is for you to train and run video analysis!\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3K9Ndy1beyfG",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# now we are ready to train!\n",
    "#should see version 2.0.8\n",
    "import deeplabcut\n",
    "deeplabcut.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> change to your path: </h1>\n",
    "<p> this should be the same path as the one in the createDLCproject notebook. The path is the path to the config.yaml file, not the project directory itself </p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z7ZlDr3wV4D1",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "path_config_file = r'F:\\MysoreData\\nbk\\mouseVideoAnalysis\\Box1\\cam2\\box1_cam1-spencerloggia-2021-04-04\\config.yaml'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xNi9s1dboEJN"
   },
   "source": [
    "## Create a training dataset\n",
    "This function generates the training data information for DeepCut (an hdf5 file) based on the pandas dataframes that hold label information. The user can set the fraction of the training set size (from all labeled image in the hd5 file) in the config.yaml file. While creating the dataset, the user can create multiple shuffles.\n",
    "\n",
    "After running this script the training dataset is created and saved in the project directory under the subdirectory **'training-datasets'**\n",
    "\n",
    "This function also creates new subdirectories under **dlc-models** and appends the project config.yaml file with the correct path to the training and testing pose configuration file. These files hold the parameters for training the network. Such an example file is provided with the toolbox and named as **pose_cfg.yaml**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "deeplabcut.create_training_dataset(path_config_file, net_type='resnet_50', augmenter_type='imgaug')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is the time to start training the network!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c4FczXGDoEJU"
   },
   "source": [
    "## Start training\n",
    "This function trains the network for a specific shuffle of the training dataset. Set `gputouse` if you want to use a specific hardware accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_pOvDq_2oEJW",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#reset in case you started a session before...\n",
    "#tf.reset_default_graph()\n",
    "\n",
    "deeplabcut.train_network(path_config_file, shuffle=1, saveiters=1000, displayiters=100, gputouse=0)\n",
    "\n",
    "#this will run until you stop it (CTRL+C), or hit \"STOP\" icon, or when it hits the end (default, 1.3M iterations). \n",
    "#Whichever you chose, you will see what looks like an error message, but it's not an error - don't worry....\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A couple tips for possible troubleshooting (1): \n",
    "\n",
    "if you get **permission errors** when you run this step (above), first check if the weights downloaded. They should be under 'init_weights' (see path in the pose_cfg.yaml file). You can enter the DOCKER in the terminal:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Troubleshooting (2): \n",
    "if it appears the training does not start (i.e. \"Starting training...\" does not print immediately),\n",
    "then you have another session running on your GPU. Go check \"nvidia-smi\" and look at the process names. You can only have 1 per GPU!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xZygsb2DoEJc"
   },
   "source": [
    "## Start evaluating\n",
    "This funtion evaluates a trained model for a specific shuffle/shuffles at a particular state or all the states on the data set (images)\n",
    "and stores the results as .csv file in a subdirectory under **evaluation-results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nv4zlbrnoEJg",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "deeplabcut.evaluate_network(path_config_file)\n",
    "\n",
    "# Here you want to see a low pixel error! Of course, it can only be as good as the labeler, so be sure your labels are good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BaLBl3TQtrfB"
   },
   "source": [
    "## There is an optional refinement step\n",
    "- if you see higher pixel errors, check the labelled videos before worrying. It's possible that misclassified points when the mouse is not in the frame are driving up error.\n",
    "- if your pixel errors are not low enough, use DLC docs on how to refine yur network!\n",
    "- You will need to adjust the labels (you can use the createDLCproject notebook)\n",
    "-  see DLC protocol instructions on how to refine your data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OVFLSKKfoEJk"
   },
   "source": [
    "## Start Analyzing videos\n",
    "This function analyzes the new video. The user can choose the best model from the evaluation results and specify the correct snapshot index for the variable **snapshotindex** in the **config.yaml** file. Otherwise, by default the most recent snapshot is used to analyse the video.\n",
    "\n",
    "Keep in mind that generating the 2D trajectories here is not required for 3D labelling. I recommend not 2d labelling all the data, maybe just a few examples for verification.\n",
    "The results are stored in hd5 file in the same directory where the video resides. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y_LZiS_0oEJl",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# adjust path to where raw vids are located. 2D label h5 files are generated in same directory.\n",
    "VIDEO_SOURCE = r\"F:\\MysoreData\\nbk\\mouseVideoAnalysis\\Box1\\cam1\\test_label\"\n",
    "video_all = os.listdir(VIDEO_SOURCE)\n",
    "video = []\n",
    "for i in range(0,len(video_all)):\n",
    "    video.append(VIDEO_SOURCE + '\\\\' + video_all[i])\n",
    "    \n",
    "deeplabcut.analyze_videos(path_config_file,video)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pCrUvQIvoEKD"
   },
   "source": [
    "## Create labeled video\n",
    "This funtion is for visualiztion purpose and can be used to create a video in .mp4 format with labels predicted by the network. This video is saved in the same directory where the original video resides. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6aDF7Q7KoEKE",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "path_config_file = r'F:\\MysoreData\\nbk\\mouseVideoAnalysis\\Box1\\cam2\\box1_cam1-spencerloggia-2021-04-04\\config.yaml'\n",
    "deeplabcut.create_labeled_video(path_config_file,video)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8GTiuJESoEKH"
   },
   "source": [
    "## Plot the trajectories of the analyzed videos\n",
    "This function plots the trajectories of all the body parts across the entire video. Each body part is identified by a unique color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gX21zZbXoEKJ",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook \n",
    "#for making interactive plots.\n",
    "#deeplabcut.plot_trajectories(path_config_file,videofile_path, plotting=True)\n",
    "\n",
    "deeplabcut.plot_trajectories(path_config_file,video,showfigures=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Colab_TrainNetwork_VideoAnalysis.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}